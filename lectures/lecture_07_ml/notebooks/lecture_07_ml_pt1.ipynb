{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:58.326022Z",
     "start_time": "2019-10-31T20:50:57.197816Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формальная постановка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T09:44:35.143558Z",
     "start_time": "2019-10-31T09:44:35.139440Z"
    }
   },
   "source": [
    "<table><tr>\n",
    "<td><img src=\"images_pt1/class1.png\" style=\"height:400px\"></td>\n",
    "<td><img src=\"images_pt1/class2.png\" style=\"height:400px\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дан набор обучающих примеров $$(x_1, x_2, \\dots, x_n), x_i \\in \\mathcal{X} \\subseteq \\mathbb{R}^k,$$ $n$ -- размер выборки, $k$ -- количество признаков (фичей). Также задан набор целевых переменных $$(y_1, y_2, \\dots, y_n), y_i \\in \\mathcal{Y} \\subseteq \\mathbb{R}.$$\n",
    "\n",
    "Наша задача построить алгоритм\n",
    "$$a: \\mathcal{X} \\to \\mathcal{Y},$$\n",
    "который будет приближать исходную зависимость $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача классификации\n",
    "Множество $\\mathcal{Y}$ конечно.\n",
    "\n",
    "Частный случай -- бинарная классификация ($|\\mathcal{Y}| = 2$), например, предсказываем будет ли клик, покупка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/class3.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо найти уравнение прямой (гиперплоскости), которая бы могла разделить два класса ($H_2$ и $H_3$ подходят). В данном случае, уравнение прямой задаётся как: $$g(x) = w_0 + w_1x[1] + w_2x[2] = \\langle w, x \\rangle + w_0 =  w^\\top x + w_0$$\n",
    "\n",
    "* Если $g(x^*) > 0$, то $y^* = \\text{'черный'} = 1$\n",
    "* Если $g(x^*) < 0$, то $y^* = \\text{'белый'} = 0$\n",
    "* Если $g(x^*) = 0$, то мы находимся на линии\n",
    "* т.е. решающее правило: $y^* = \n",
    "\\begin{cases}\n",
    "1, &\\text{если } g(x^*) > 0,\\\\\n",
    "0, &\\text{если } g(x^*) < 0.\n",
    "\\end{cases}$\n",
    "\n",
    "Некоторые геометрические особенности\n",
    "* $\\frac{w_0}{||w||}$ - расстояние от начала координат то прямой\n",
    "* $\\frac{|g(x)|}{||w||}$ - расстояние от точки $x$ до гиперплоскости, степень \"уверенности\" в классификациий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Значит нам надо просто минимизировать ошибки классификации для всех объектов:\n",
    "\n",
    "$$L(w) = \\sum_{i: y_i = 0} [g(x_i) > 0] + \\sum_{i: y_i = 1} [g(x_i) < 0] \\rightarrow \\min_w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что это будет комбинаторная оптимизация. Существуют различные аппроксимации этой функции ошибок:\n",
    "<center><img src='http://jaquesgrobler.github.io/Online-Scikit-Learn-stat-tut/_images/plot_sgd_loss_functions_11.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию $$\\sigma(z) = \\frac{1}{1 + exp{(-z)}},$$она называется **сигмойда**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:58.781461Z",
     "start_time": "2019-10-31T20:50:58.329475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAF3CAYAAADgjOwXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XXWd//H3596btUnadEmXpKErXSiFLrRsKptSQCgIOsD4E4Gx44LOjDPO4IyD/nAWdR6jv58j6g9RAWUHLQWLCIKArKU03bd0T9M2TdOmTdIs997v7497Wy4haVOae865976ej0fIued+b3if3iXvnNWccwIAAEAwhPwOAAAAgHdRzgAAAAKEcgYAABAglDMAAIAAoZwBAAAECOUMAAAgQChnAAAAAUI5AwAACBDKGQAAQIBQzgAAAAIk4neAkzF06FA3ZswYv2MAAAAc19KlSxudc8OONy6jy9mYMWP09ttv+x0DAADguMxsW1/GsVkTAAAgQChnAAAAAUI5AwAACBDKGQAAQIBQzgAAAAKEcgYAABAglDMAAIAAoZwBAAAECOUMAAAgQDwpZ2b2CzNrMLNVvdxvZvZDM6s1sxVmNtOLXAAAAEHj1ZqzeyXNO8b9l0mamPxaIOknHmQCAAAIHE+uremce9nMxhxjyHxJ9zvnnKQ3zGyQmY10zu3yIh8AANkgHneKOae4c4rHlTLtFHdKTDsnd3Q68Rjp3dsu+V06Mk5yyekjj5MS00fnK/E4l5yf8O59Spl/ZNx75illoN4z+d4x3eal6mGWXA8DexonSeOHlqh6SHEv93orKBc+r5S0I+V2XXLe+8qZmS1QYu2aqqurPQkHAEAq55zau+Jq7YyqtSOqts6Y2jpjau+K6XBnTG1diemOrpjau+LqiL77vTMaV2csrs6oU2csrq5oXF2xxLyuWFxdMXf0eyweVzTm1BWPKxZzisadYskCdvR2snxF473VDvTF7ZdN1uc/Mt7vGJKCU86sh3k9vsqcc3dLuluSZs+ezSsRAPCBdURjamzp1L6WDjW1dupAW5f2t3Vqf1uXDrR16uDhLh1sj+rg4S4dao/qYHuXWjoShexEu5CZVBAJqSASVn4kpPxwSAWRkPLCIeVHQoqETXnhkIrywiotjCgSCikvbAqHEvMT300hM0VCpnAopHBICoWSt80USvkeMkvcb0emTSGTLHk7Md3DbZnMEo87+j2ZX8n7ErffnX/kcUq5LzE65b6jPyP5S//o9Lv3pZaBIz/jfY/rNq/bv3KP/+7HHyWNGlTU0w/0RVDKWZ2k0Sm3qyTV+5QFAJDhnHPa39alHU1t2tXcrt3Nh7WruT0xfbBdjYc6tLelQ4faoz0+3kwqK8zTwKI8lRVFVFqQpzFDi1VamKeSgogGFIQ1oCCSmM6PqDg/rKL8sIryEt+L88MqiIRVmBdWYV6ikOWF7T2FA+hNUMrZIkm3mdnDkuZKamZ/MwDA8TQf7lJtQ4tqGw5p895WbdvXpu1Nia+WjvcWr/xwSMMHFmhkWZGmjCzTh0ryNay0QENLEl/lA/JVXpyn8uJ8lRXlKRyiSMEfnpQzM3tI0gWShppZnaRvSsqTJOfcTyUtlnS5pFpJbZJu9iIXACAzxONOmxtbtbq+WSvrmrVu9yFtbDikPQc7jo7Jj4Q0urxI1YOLddaYclUPGaCq8iJVDirSiIGFGlycrxCFCxnAq6M1bzjO/U7Sl7zIAgAIvua2Li3Z2qS3tjapZvsBra5vVmtnTFJiv61JI0p1/oRhmji8RBMrSjSxolSV5UWs7UJWCMpmTQBADjvU3qU/b2zU65v36a0tTVq/55CcS2yKPK2yTNfNqtJplQN1euVATagoUV6YC9wge1HOAACec85p095WvbiuQS+sa9CSrU2Kxp2K88OadUq5rjh9pOaMHawzRg9SYV7Y77iApyhnAADPbNrboieX7dSi5fXauq9NkjRpeKn+6kPjdNHkCs2oHsRaMeQ8yhkAIK32HGzXU8vr9WRNvVbubJaZdO74Ibr1/LG6cHKFqsqDcVZ2ICgoZwCAfuec05tbmnTfa1v17OrdijtpetVAfeOKKbryjFEaXlbod0QgsChnAIB+c7gzpidrdure17Zq3e5DGlScpwUfHq9Pzq7S+GElfscDMgLlDABw0lo7orr3ta362SubdaCtS1NGlum7156u+WdWskM/cIIoZwCAD6y9K6Zfv7FNP/7TJjW1duriyRVa8OFxmjN2MJcqAj4gyhkA4IR1RuN6eMl2/eiFWjUc6tCHJg7VVz96qmZUl/sdDch4lDMAwAl5c/M+fWPhKm1saNGcMYP1PzfM0NxxQ/yOBWQNyhkAoE+aWjv1n4vX6rGldaocVKR7PjNbF0+pYPMl0M8oZwCAY4rHnR5bukP/+cw6tbRH9YULxuvLF01QcT6/QoB04J0FAOjV3kMd+uqjNXplY6POGlOuf7/mdJ06vNTvWEBWo5wBAHr0542N+ttHanSovUv/dvU03TinWqEQmzCBdKOcAQDeIxqL6wfPb9CP/7RJE4aV6IG/mqtJI1hbBniFcgYAOKr+wGF95aFlenvbfl1/1mh988rTVJTPSWQBL1HOAACSpJV1zbrlviU63BnTD2+YoavOGOV3JCAnUc4AAHpxXYO+9OA7Ki/O10NfmqsJFWzGBPxCOQOAHPfAm9v0rwtXaeqoMv3is2eporTQ70hATqOcAUCOised/usP6/WTP23ShZOG6Uc3ztSAAn4tAH7jXQgAOSgWd/ra48v1m3d26sa51brzqtMUCYf8jgVAlDMAyDnxuNPtT6zQb97Zqb+75FR95eIJXIIJCBDKGQDkEOec/vXJVXpsaZ2+cvFE/c0lE/2OBKAb1mEDQI5wzunOp9fogTe3668/Mk5/RzEDAolyBgA5wDmn7/5+vX756lZ99twxun3eZDZlAgFFOQOAHPDDP9bqpy9t0o1zq/XNK6dSzIAAo5wBQJZbuGynfvD8Bn1iRqX+bf40ihkQcJQzAMhiy7bv1z8+sUJzxg7Wd66drlCIYgYEHeUMALLUrubDWvCrpaooLdBPPz1L+RE+8oFMwDsVALLQ4c6YFty/VG0dUf38prM0eEC+35EA9BHnOQOALONc4uz/q+qb9bP/NVuTRnARcyCTsOYMALLMj16o1dMrdukfL52sS6YO9zsOgBNEOQOALPJabaO+//wGXTOjUp//yDi/4wD4AChnAJAlDrR16quPLtfYoQP079dwygwgU1HOACALOOf09d+s1L7WDv3w+hkqzmeXYiBTUc4AIAs8trROz6zarb//2CRNqxzodxwAJ4FyBgAZbktjq761aLXOGTdECz7EfmZApqOcAUAG64rF9bcPL1NeOKT//tQZXAEAyALslAAAGez/Pr9Ry+uaddeNMzVqUJHfcQD0A9acAUCGWr7jgH78p1p9claVrpg+0u84APoJ5QwAMlA0Ftc//3alhpYU6I4rp/odB0A/opwBQAa6//VtWl1/UN+88jSVFub5HQdAP6KcAUCG2d3crv/+w3p95NRhuvz0EX7HAdDPKGcAkGH+91OrFY07fXs+VwEAshHlDAAyyAvr9uiZVbv1lYsnqnpIsd9xAKQB5QwAMsThzpjueHK1JlSU6HOcbBbIWpznDAAyxA9f2Ki6/Yf1yIKzlR/hb2sgW/HuBoAMUNtwSD97ebOum1WlueOG+B0HQBpRzgAgA3znmfUqygvr65dN9jsKgDSjnAFAwC3Z2qTn1+7R5y8YryElBX7HAZBmnpUzM5tnZuvNrNbMbu/h/moze9HMlpnZCjO73KtsABBUzjn9x+K1Gl5WoFvOG+t3HAAe8KScmVlY0l2SLpM0VdINZtb9eiPfkPSoc26GpOsl/diLbAAQZM+u3q1l2w/o7y45VUX5Yb/jAPCAV2vO5kiqdc5tds51SnpY0vxuY5yksuT0QEn1HmUDgEDqisX1vd+v18SKEl03q8rvOAA84tWpNCol7Ui5XSdpbrcx35L0BzP7sqQBki7xJhoABNMjS3Zoc2Or7vnMbEXC7CIM5Aqv3u09XV/Edbt9g6R7nXNVki6X9Csze18+M1tgZm+b2dt79+5NQ1QA8F9rR1T/5/mNmjNmsC6eUuF3HAAe8qqc1UkanXK7Su/fbHmrpEclyTn3uqRCSUO7/yDn3N3OudnOudnDhg1LU1wA8Nc9r2xRY0uHbr98MtfPBHKMV+VsiaSJZjbWzPKV2OF/Ubcx2yVdLElmNkWJcsaqMQA5p7GlQ3e/vEmXTRuhmdXlfscB4DFPyplzLirpNknPSlqrxFGZq83sTjO7Kjns7yV9zsyWS3pI0medc903fQJA1vt/L21SezSur106ye8oAHzg2bU1nXOLJS3uNu+OlOk1ks7zKg8ABFFTa6d+/cZ2zT9jlMYNK/E7DgAfcPgPAATIL/68Re3RmL544Xi/owDwCeUMAAKi+XCX7nttqy6fNlITKkr9jgPAJ5QzAAiI+1/bqkMdUX3pwgl+RwHgI8oZAARAa0dUP391iy6eXKGpo8qO/wAAWYtyBgAB8MCb23SgrUtfuoi1ZkCuo5wBgM/au2K6++UtOn/CUM5rBoByBgB+e2TJDjW2dOg21poBEOUMAHzVGY3rpy9t0lljyjV37GC/4wAIAMoZAPjot8vqtKu5XbddNJFraAKQRDkDAN8453TPK1s0dWSZPjxxqN9xAAQE5QwAfPLn2kZtbGjRLeePZa0ZgKMoZwDgk1++ulVDS/J15Rkj/Y4CIEAoZwDgg817W/TCugZ9+uxTVBAJ+x0HQIBQzgDAB/e+tlX54ZD+cu4pfkcBEDCUMwDwWHNblx57u05XnTlKw0oL/I4DIGAoZwDgsUfe3q7DXTHdfN4Yv6MACCDKGQB4KBqL677XtunscYN12qiBfscBEECUMwDw0B/W7NHOA4d1y3lj/Y4CIKAoZwDgoV++ukXVg4t18ZThfkcBEFCUMwDwyIq6A1qydb8+e+4YhUOcdBZAzyhnAOCRe1/bqpKCiD45u8rvKAACjHIGAB440Napp1fs0jUzKlVamOd3HAABRjkDAA888c5OdUbjumFOtd9RAAQc5QwA0sw5p4fe2q4zRw/S1FFlfscBEHCUMwBIsyVb96u2oUU3zmWtGYDjo5wBQJo9+OY2lRZGdOX0UX5HAZABKGcAkEb7Wzu1eNVuXTOjUkX5Yb/jAMgAlDMASKMn3qlTZzTOJk0AfUY5A4A0cc7pwbe2a2b1IE0ewYEAAPqGcgYAafLmliZt3tvK6TMAnBDKGQCkyYNvbldpYUQf50AAACeAcgYAadDU2qnfr9qta2dWcSAAgBNCOQOANHhiaZ06Y1wRAMCJo5wBQD9zzunhJds165RyTRpR6nccABmGcgYA/axmxwFt2tuqT82u8jsKgAxEOQOAfvb40joV5oV0+ekj/Y4CIANRzgCgH7V3xbRoeb0umzZSpYV5fscBkIEoZwDQj55bs0eH2qO6diabNAF8MJQzAOhHjy+t06iBhTpn/BC/owDIUJQzAOgnew6265WNe/WJmVUKh8zvOAAyFOUMAPrJb5ftVNxJ185ikyaAD45yBgD9wDmnx5fWafYp5Ro7dIDfcQBkMMoZAPSD5XXNqm1o0XWsNQNwkihnANAPHl+6I3Fus+mc2wzAyaGcAcBJau+KaVFNveadNkJlnNsMwEminAHASXp+7R4dbI/qulmj/Y4CIAtQzgDgJHFuMwD9iXIGACdh76EOvbxhr66eUcm5zQD0C8oZAJyEp1fUK+6ka2ZU+h0FQJagnAHASVi4bKemjizTxOGlfkcBkCU8K2dmNs/M1ptZrZnd3suYT5nZGjNbbWYPepUNAD6ILY2tWl7XrKtnjPI7CoAsEvHif2JmYUl3SfqopDpJS8xskXNuTcqYiZK+Luk859x+M6vwIhsAfFALl+2UmXTVGWzSBNB/vFpzNkdSrXNus3OuU9LDkuZ3G/M5SXc55/ZLknOuwaNsAHDCnHN6smanzhk3RCMGFvodB0AW8aqcVUrakXK7Ljkv1amSTjWzV83sDTOb51E2ADhhNTsOaOu+Nl19JmvNAPQvTzZrSurp+HLX7XZE0kRJF0iqkvSKmU1zzh14zw8yWyBpgSRVV1f3f1IA6IMna+qVHwlp3ukj/I4CIMt4teasTlLqqbOrJNX3MOZJ51yXc26LpPVKlLX3cM7d7Zyb7ZybPWzYsLQFBoDeRGNxPb2iXhdPruByTQD6nVflbImkiWY21szyJV0vaVG3MQslXShJZjZUic2cmz3KBwB99ufaRjW2dOpqzm0GIA08KWfOuaik2yQ9K2mtpEedc6vN7E4zuyo57FlJ+8xsjaQXJX3NObfPi3wAcCKerKlXWWFEF0xi7T2A/ufVPmdyzi2WtLjbvDtSpp2krya/ACCQ2jqjenb1bs0/c5QKImG/4wDIQlwhAABOwHNr9qitM8ZRmgDShnIGACdg4bKdGjWwUGeNGex3FABZinIGAH3U1Nqplzc26qozKxUK9XSGIAA4eZQzAOijxSt3KRZ3uuoMrqUJIH0oZwDQR4uW12tCRYmmjCz1OwqALEY5A4A+2NV8WEu2NunK6aNkxiZNAOlDOQOAPvjdil1yTrryjJF+RwGQ5ShnANAHTy2v17TKMo0bVuJ3FABZjnIGAMextbFVy+uaORAAgCcoZwBwHE+vqJckfXw65QxA+lHOAOA4Fi2v11ljyjVqUJHfUQDkAMoZABzD+t2HtGFPC5s0AXiGcgYAx7Bo+U6FQ6bLTucoTQDeoJwBQC+cc3pq+S6dO36IhpYU+B0HQI6gnAFAL5bXNWt7U5uuZJMmAA9RzgCgF4tq6pUfDunS00b4HQVADjnhcmZmA8wsnI4wABAUsbjT71bW6yOThmlgUZ7fcQDkkOOWMzMLmdmNZvY7M2uQtE7SLjNbbWb/ZWYT0x8TALy1ZGuT9hzsYJMmAM/1Zc3Zi5LGS/q6pBHOudHOuQpJH5L0hqTvmNmn05gRADz31PJ6FeWFdcmUCr+jAMgxkT6MucQ512Vm10paeWSmc65J0hOSnjAz1vkDyBrRWFzPrNqti6dUqDi/Lx+TANB/jrvmzDnXlZz8taQHU/c3M7Obu40BgIz32qZ9amrtZJMmAF+cyAEB6yS9pPeuKfty/0cCAH89tbxepQURfeTUYX5HAZCDTqScOefcTyX9RtIiMyuSZOmJBQD+6IjG9PvVu/XR04arMI8D0wF470R2ptgvSc65+82sTdLvJBWnJRUA+OSVDY061B5lkyYA3/S5nDnnLk6ZftzM2iXdm45QAOCXp1bUa1Bxns6fMNTvKAByVF/Oc9bjpkvn3NPOuaHHGgMAmeRwZ0zPrdmjy6aNUF6YC6gA8EefznNmZl82s+rUmWaWb2YXmdl9km5KTzwA8M6L6xvU1hnTldPZpAnAP33ZrDlP0i2SHjKzcUrse1akRLH7g6QfOOdq0hcRALzx1PJ6DS0p0NxxQ/yOAiCHHbecOefaJf3YzIZJ+k9JQyQdds4dSHc4APBKS0dUL6xr0PVnjVY4xJ4aAPxzIkdr3qHE0ZmDJb1jZg9R0ABki+fX7FFHNM5RmgB8d6J7vLZLelbSaEmvm9mZ/R8JALz31PJ6jRpYqJnV5X5HAZDjTmTN2Trn3DeT04+b2b2Sfirpon5PBQAeam7r0ssb9+qz545RiE2aAHx2ImvOGs1s1pEbzrkNkri2CYCM9/vVu9QVc2zSBBAIJ7Lm7CuSHjazpZJWSpouaUtaUgGAhxYtr9eYIcU6vXKg31EAoO9rzpxzyyWdKemh5KwXJd2QjlAA4JWGQ+16fdM+XXnGKHE+bQBBcCJrzuSc61Dimpq/S08cAPDW4hW7FHfSVWzSBBAQXJ8EQE57asUuTR5RqonDS/2OAgCSKGcAcljd/jYt3bafAwEABArlDEDOenrFLkniWpoAAoVyBiBnLaqp15mjB6l6SLHfUQDgKMoZgJxU29CiNbsOskkTQOBQzgDkpKeW18tM+vj0kX5HAYD3oJwByDnOOT21vF5njx2i4WWFfscBgPegnAHIOavrD2pzYyubNAEEEuUMQM55anm9IiHTZdNG+B0FAN6HcgYgp8TjiU2aH5o4VOUD8v2OAwDvQzkDkFPe2b5f9c3tuupMNmkCCCbKGYCcsrBmpwrzQvroVDZpAggmyhmAnNEVi+t3K3bpkinDVVIQ8TsOAPSIcgYgZ7y8Ya/2t3Xp6jMr/Y4CAL3yrJyZ2TwzW29mtWZ2+zHGXWdmzsxme5UNQG5YWFOv8uI8ffjUYX5HAYBeeVLOzCws6S5Jl0maKukGM5vaw7hSSV+R9KYXuQDkjpaOqJ5bs1tXTB+p/AgbDQAEl1efUHMk1TrnNjvnOiU9LGl+D+O+Lel7kto9ygUgRzy7arfau+Js0gQQeF6Vs0pJO1Ju1yXnHWVmMySNds497VEmADlkYc1OVZUXadYp5X5HAYBj8qqcWQ/z3NE7zUKSfiDp74/7g8wWmNnbZvb23r17+zEigGzVcKhdr9Y26uozK2XW08cRAASHV+WsTtLolNtVkupTbpdKmibpT2a2VdLZkhb1dFCAc+5u59xs59zsYcPYqRfA8T21fJfiTrp6BieeBRB8XpWzJZImmtlYM8uXdL2kRUfudM41O+eGOufGOOfGSHpD0lXOubc9ygcgiz1Zs1PTKss0oaLU7ygAcFyelDPnXFTSbZKelbRW0qPOudVmdqeZXeVFBgC5afPeFq2oa+ZAAAAZw7NTZDvnFkta3G3eHb2MvcCLTACy38KaeplJV57BJk0AmYGT/QDIWs45PVmzU+eOH6LhZYV+xwGAPqGcAchay3Yc0LZ9bWzSBJBRKGcAstbCZTtVEAlp3rQRfkcBgD6jnAHISh3RmJ6sqde8aSNUWpjndxwA6DPKGYCs9Me1DWo+3KXrZlX5HQUATgjlDEBWenxpnUaUFerc8UP9jgIAJ4RyBiDrNBxs10sb9uoTMysVDnG5JgCZhXIGIOssrNmpWNzpWjZpAshAlDMAWcU5p8eX1mlm9SCNH1bidxwAOGGUMwBZZeXOZm3Y06LrZo32OwoAfCCUMwBZ5fGldSqIhHTF9JF+RwGAD4RyBiBrHDm32aWnjdDAIs5tBiAzUc4AZA3ObQYgG1DOAGSNI+c2O28C5zYDkLkoZwCyAuc2A5AtKGcAssJvl3FuMwDZgXIGIOM55/TIkh2adUo55zYDkPEoZwAy3hubm7S5sVU3zqn2OwoAnDTKGYCM9+Bb21VWGOHcZgCyAuUMQEbb19Kh36/apU/MrFJhXtjvOABw0ihnADLaE+/UqSvm9Jdz2aQJIDtQzgBkLOecHnprh84aU66Jw0v9jgMA/YJyBiBjvb5pn7Y0tuoGDgQAkEUoZwAy1gNvbdfAojxdfjoHAgDIHpQzABmpsaVDf1i9W9dyIACALEM5A5CRHl+aOBDgxrmj/Y4CAP2KcgYg48TjTg+9tV1zxgzWhAoOBACQXShnADLOa5v2adu+Nt3I6TMAZCHKGYCM8+Bb2zSoOE/zpo3wOwoA9DvKGYCMsvPAYT27eo8+NXs0BwIAyEqUMwAZ5f7Xt0qSbjp3jJ8xACBtKGcAMkZbZ1QPvbld804bocpBRX7HAYC0oJwByBhPvLNTB9ujuuX8MX5HAYC0oZwByAjxuNMvX92iM6oGamZ1ud9xACBtKGcAMsJLG/dq895W3XL+WJmZ33EAIG0oZwAywi/+vEXDywp02TSuowkgu1HOAATehj2H9MrGRn3mnDHKj/CxBSC78SkHIPB++epWFURCumEOVwQAkP0oZwACbX9rp37zTp2umVGpwQPy/Y4DAGlHOQMQaA8t2a6OaFw3nzfW7ygA4AnKGYDA6ojGdN9rW3X+hKGaNKLU7zgA4AnKGYDAenxpnfYc7NAXLhjvdxQA8AzlDEAgdcXi+smfNmlG9SCdO36I33EAwDOUMwCB9GRNver2H9ZtF07gpLMAcgrlDEDgxOJOP36xVlNGlumiyRV+xwEAT1HOAATO4pW7tLmxVV++iLVmAHIP5QxAoMTjTj96oVYTKko077QRfscBAM9RzgAEyvNr92j9nkP60oXjFQqx1gxA7qGcAQgM55x+9GKtqgcX68rpo/yOAwC+oJwBCIyXNzZqRV2zvnjBeEXCfDwByE18+gEIBOecfvTCRo0cWKhPzKzyOw4A+MazcmZm88xsvZnVmtntPdz/VTNbY2YrzOyPZnaKV9kA+O9P6/dqydb9+sIF45Uf4e9GALnLk09AMwtLukvSZZKmSrrBzKZ2G7ZM0mzn3HRJj0v6nhfZAPgvFnf6zjPrdMqQYl1/VrXfcQDAV179eTpHUq1zbrNzrlPSw5Lmpw5wzr3onGtL3nxDEts1gBzxm3fqtH7PIX3t0kmsNQOQ87z6FKyUtCPldl1yXm9ulfRMWhMBCIT2rpi+/9wGnVE1UFecPtLvOADgu4hH/5+eTlbkehxo9mlJsyV9pJf7F0haIEnV1Wz+ADLdva9t1a7mdn3/U2dyNQAAkHdrzuokjU65XSWpvvsgM7tE0r9Iuso519HTD3LO3e2cm+2cmz1s2LC0hAXgjf2tnbrrxVpdOGmYzhk/xO84ABAIXpWzJZImmtlYM8uXdL2kRakDzGyGpP+nRDFr8CgXAB/d9WKtWjuiuv2yKX5HAYDA8KScOeeikm6T9KyktZIedc6tNrM7zeyq5LD/klQi6TEzqzGzRb38OABZYEdTm+5/fZuunVmlSSNK/Y4DAIHh1T5ncs4tlrS427w7UqYv8SoLAP99/7kNMpO++rFT/Y4CAIHCMesAPFez44AW1uzUzeeN1ciBRX7HAYBAoZwB8FQ0Ftc//2alKkoL9KULx/sdBwACx7PNmgAgJU6dsWbXQf3kL2eqtDDP7zgAEDisOQPgmfoDh/X95zbowknDNG/aCL/jAEAgUc4AeObOp9Yo7pzunD+NE84CQC8oZwA88ce1e/T71bv1lYsnavTgYr/jAEBgUc4ApF1bZ1R3PLlaEytK9Ffnj/M7DgAEGgcEAEi7H/6xVjsPHNajf32O8iP8TQgAx8KnJIAeh1g6AAAQd0lEQVS0Wl3frHte2axPza7SnLGD/Y4DAIFHOQOQNoc7Y/qbh2s0eEC+vs71MwGgT9isCSBt/mPxWtU2tOjXt85V+YB8v+MAQEZgzRmAtPjj2j361Rvb9LkPjdX5E4f6HQcAMgblDEC/azjUrn98fIWmjCzTP1w6ye84AJBR2KwJoF855/S1x1aopSOqh68/UwWRsN+RACCjsOYMQL+677WtemnDXn3jiimaOLzU7zgAkHEoZwD6zdpdB/Ufz6zTRZMr9OmzT/E7DgBkJMoZgH6xr6VDf3Xf2yovztP3rpvOtTMB4ANinzMAJ60zGtfnf71UjS0deuzz52hoSYHfkQAgY1HOAJwU55z+deEqLdm6Xz+8YYamVw3yOxIAZDQ2awI4Kb98daseeXuHvnzRBF11xii/4wBAxqOcAfjAXtqwV//2uzW69LTh+rtLTvU7DgBkBcoZgA+ktqFFtz34jk4dXqrvf+pMhUIcAAAA/YFyBuCEbd/Xpk/f86YKIiHdc9NsDShg91UA6C98ogI4ITsPHNYNP3tD7dGYHl5wtqrKi/2OBABZhTVnAPpsz8F23fizN3SwvUu/vnWuJo8o8zsSAGQdyhmAPtl7qEM3/uwNNR7q0P23zNG0yoF+RwKArMRmTQDH1dTaqU/f86bqD7TrvlvmaEZ1ud+RACBrUc4AHNOOpjbdfO8S7Whq0y8/e5bmjB3sdyQAyGqUMwC9WlnXrJvvXaLOaEz33jxH54wf4nckAMh6lDMAPXph3R596YFlGjwgXw99bq4mDi/1OxIA5ATKGYD3+fUb23THk6s0dVSZfvHZs1RRWuh3JADIGZQzAEd1xeL67jPrdM+ft+iiyRX6nxtmcIJZAPAYn7oAJCV2/P/yQ8tUs+OAPnPOKbrj41MVCXO2HQDwGuUMgBav3KV/emKF5KS7bpypK6aP9DsSAOQsyhmQw9q7Yvr202v0wJvbdcboQfrRDTM0ejCXYwIAP1HOgBz11pYm/fNvV6q2oUV//ZFx+oePTVIemzEBwHeUMyDHNLV26j8Xr9VjS+tUOahI998yRx8+dZjfsQAASZQzIEfE406PL63TfzyzVi3tUX3hgvH6ykUTVZQf9jsaACAF5QzIAW9u3qfvPbteS7ft11ljyvXv15yuUzmpLAAEEuUMyGLLtu/X95/boFc2NqqitEDfu3a6rptVpVDI/I4GAOgF5QzIQqt2NusHz23QH9c1aMiAfH3jiin69NmnqDCPTZgAEHSUMyBLRGNxPb+2Qfe+tkVvbG5SWWFEX7t0kj577hjO8g8AGYRPbCDDHWjr1MNLduhXr2/TzgOHVTmoSP80b7JunFutgUV5fscDAJwgyhmQgTqjcb20Ya8W1uzU82v2qCMa19njButfPz5Vl0yp4LJLAJDBKGdAhojFnd7e2qSFNfVavHKXmg93afCAfP3FWaN149xqTR5R5ndEAEA/oJwBAXagrVMvbdirF9c16KUNe7W/rUtFeWFdetpwzT+zUudPHMpZ/QEgy1DOgAA53BnTsh379daWJr1a26il2/Yr7qTy4jxdMKlCF02u0MVTKlScz1sXALIVn/CAT5xz2tXcrpU7m7Vs+wG9tWWfVu5sVlfMyUyaOrJMX7xggi6cXKEzRw9SmHOTAUBOoJwBHuiMxrVtX6s2NrRoTf1BrdzZrFU7m7WvtVOSFAmZplcN1K3nj9PcsYM185RyjrQEgBxFOQP6SSzutPtgu7bva9P2plZt29emzXtbtbHhkLbta1M07iRJ4ZBpYkWJLpxcodMrB2pa5UBNHVnGNS4BAJI8LGdmNk/S/5UUlnSPc+473e4vkHS/pFmS9kn6C+fcVq/yAcfS3hXT3kMdamzpUGNLp3YfbNeuA4e1u7ldu5rbtav5sOoPtKszFj/6mEjIVD24WBMqSjRv2ghNrCjVhIoSjR9WQhEDAPTKk3JmZmFJd0n6qKQ6SUvMbJFzbk3KsFsl7XfOTTCz6yV9V9JfeJEPuaEzGldrR1StnVG1dER1qD2qg4e7dLC9S4fao2pu69L+ti4daOvUgcNd2t/Wqf2tnWps6VRLR/R9Py8SMg0vK9TIgYU6rXKg5k0bqerBxTplSLGqBxdr5MBCzjcGADhhXq05myOp1jm3WZLM7GFJ8yWllrP5kr6VnH5c0o/MzJxzzqOM+ICcc4rFneJOiienY84pHk+dlqLxuGJxp2hyfjSW+N4Vjysac4qmfO+MOnXF4orG4+qKOnXE4uqMJr66ktMd0Zjau977/XBXXO2dMR3uiqmtM6r2rrhaO6Nq64i9Z61WbwbkhzWoOF+DivNUXpyvykFFGlpSoGGlBRpakq+hJQUaWlKgkQMLNaSkgJ30AQD9zqtyVilpR8rtOklzexvjnIuaWbOkIZIaPUnYgzc279N3f7/uffN7qos9NsiUge79s+RSHnVk/nvvPzLv/T/duXcfn5h+d5xL/ufIPJcy3rnU/1eiUB2ZH08+0CVLlpMUj3e7feQxye+xuD/dORwyFURCKoiEVJgXfs/3ovywhpUWqCivWEX5YRXnhzWgIKIBR74XRFRSEFFpYURlhXkqK8pTaWHidkGEzY0AAH95Vc56Wr3Q/bd6X8bIzBZIWiBJ1dXVJ5/sGPLCppJeLhht9v64PS1A6jA7Os/eN++9Y+1983oaZ7J3py1xWynjzSz5/b23lRwbsncfZ5a8Pzk2ZEfuN4VS5odDlpz37phQKDEmcZ8UTk4fmRcKmcJmioRNkVBiXjiUmI6EQgqHTXmh0NH788Kh5FdiOhI25UdCKgiHlR8JKT8SYo0VACBreVXO6iSNTrldJam+lzF1ZhaRNFBSU/cf5Jy7W9LdkjR79uy0rraZdcpg/erW7iv4AAAA0servZWXSJpoZmPNLF/S9ZIWdRuzSNJNyenrJL3A/mYAACDXeLLmLLkP2W2SnlXiVBq/cM6tNrM7Jb3tnFsk6eeSfmVmtUqsMbvei2wAAABB4tl5zpxziyUt7jbvjpTpdkmf9CoPAABAEHESJgAAgAChnAEAAAQI5QwAACBAKGcAAAABQjkDAAAIEMoZAABAgFDOAAAAAoRyBgAAECCUMwAAgAChnAEAAASIZfK1xc1sr6Rtaf7fDJXUmOb/R5Dl8vLn8rJLub38LHvuyuXlz+Vll7xZ/lOcc8OONyijy5kXzOxt59xsv3P4JZeXP5eXXcrt5WfZc3PZpdxe/lxedilYy89mTQAAgAChnAEAAAQI5ez47vY7gM9yeflzedml3F5+lj135fLy5/KySwFafvY5AwAACBDWnAEAAAQI5UySmX3SzFabWdzMZne77+tmVmtm683s0l4eP9bM3jSzjWb2iJnle5O8/yXz1yS/tppZTS/jtprZyuS4t73OmQ5m9i0z25my/Jf3Mm5e8vVQa2a3e50zXczsv8xsnZmtMLPfmtmgXsZlzXN/vOfSzAqS74na5Ht8jPcp+5+ZjTazF81sbfKz7296GHOBmTWnvB/u8CNruhzvdWwJP0w+9yvMbKYfOfubmU1KeU5rzOygmf1ttzFZ9dyb2S/MrMHMVqXMG2xmzyV/bz9nZuW9PPam5JiNZnaTZ6Gdczn/JWmKpEmS/iRpdsr8qZKWSyqQNFbSJknhHh7/qKTrk9M/lfQFv5epn/5d/lvSHb3ct1XSUL8z9vPyfkvSPxxnTDj5OhgnKT/5+pjqd/Z+Wv6PSYokp78r6bvZ/Nz35bmU9EVJP01OXy/pEb9z99Oyj5Q0MzldKmlDD8t+gaSn/c6axn+DY76OJV0u6RlJJulsSW/6nTkN/wZhSbuVOPdW1j73kj4saaakVSnzvifp9uT07T193kkaLGlz8nt5crrci8ysOZPknFvrnFvfw13zJT3snOtwzm2RVCtpTuoAMzNJF0l6PDnrPklXpzOvF5LL9SlJD/mdJWDmSKp1zm12znVKeliJ10nGc879wTkXTd58Q1KVn3k80Jfncr4S72kp8R6/OPneyGjOuV3OuXeS04ckrZVU6W+qwJkv6X6X8IakQWY20u9Q/exiSZucc+k+mbuvnHMvS2rqNjv1vd3b7+1LJT3nnGtyzu2X9JykeWkLmoJydmyVknak3K7T+z/Ahkg6kPJLracxmehDkvY45zb2cr+T9AczW2pmCzzMlW63JTdh/KKX1dx9eU1kg1uUWGvQk2x57vvyXB4dk3yPNyvxns8ayU21MyS92cPd55jZcjN7xsxO8zRY+h3vdZwL7/Xr1fsf4Nn83EvScOfcLinxx4qkih7G+PYaiHjxPwkCM3te0oge7voX59yTvT2sh3ndD2/ty5hA6eO/xQ069lqz85xz9WZWIek5M1uX/Osk0I617JJ+IunbSjx/31Zis+4t3X9ED48N9POdqi/PvZn9i6SopAd6+TEZ+dz3ICvf3yfCzEokPSHpb51zB7vd/Y4Sm7takvtfLpQ00euMaXS813G2P/f5kq6S9PUe7s72576vfHsN5Ew5c85d8gEeVidpdMrtKkn13cY0KrG6O5L8y7qnMYFyvH8LM4tI+oSkWcf4GfXJ7w1m9lslNhEF/hd0X18HZvYzSU/3cFdfXhOB1Yfn/iZJH5d0sUvudNHDz8jI574HfXkuj4ypS74vBur9m0cykpnlKVHMHnDO/ab7/allzTm32Mx+bGZDnXNZce3FPryOM/q93geXSXrHOben+x3Z/twn7TGzkc65XcnN1Q09jKlTYv+7I6qU2Dc97diseWyLJF2fPGJrrBJ/ObyVOiD5C+xFSdclZ90kqbc1cZniEknrnHN1Pd1pZgPMrPTItBI7kq/qaWwm6bY/yTXqeZmWSJpoiSN085XYLLDIi3zpZmbzJP2TpKucc229jMmm574vz+UiJd7TUuI9/kJvpTWTJPeb+7mktc657/cyZsSR/evMbI4Svy/2eZcyffr4Ol4k6TPJozbPltR8ZDNYluh160g2P/cpUt/bvf3eflbSx8ysPLmby8eS89LPi6MOgv6lxC/iOkkdkvZIejblvn9R4oiu9ZIuS5m/WNKo5PQ4JUpbraTHJBX4vUwn+e9xr6TPd5s3StLilOVdnvxarcQmMd9z98Ny/0rSSkkrlHjjjuy+7MnblytxdNumbFn25HLVKrF/RU3y68hRiln73Pf0XEq6U4mCKkmFyfd0bfI9Ps7vzP203OcrsXlmRcrzfbmkzx9570u6LfkcL1fiAJFz/c7dj8vf4+u42/KbpLuSr42VSjmSP9O/JBUrUbYGpszL2udeiRK6S1JX8nf9rUrsO/pHSRuT3wcnx86WdE/KY29Jvv9rJd3sVWauEAAAABAgbNYEAAAIEMoZAABAgFDOAAAAAoRyBgAAECCUMwAAgAChnAEAAAQI5QwAACBAKGcAkGRmL5hZTfKr3cw+6XcmALmHk9ACQDdm9gVJF0q6wTkX8zsPgNySMxc+B4C+MLPPKHFR6GspZgD8QDkDgKTkZsy/lDTfOdfldx4AuYlyBgCSzOzjkr4o6ePOuXa/8wDIXexzBgCSzGyfpCZJrclZ/+Oc+7mPkQDkKMoZAABAgHAqDQAAgAChnAEAAAQI5QwAACBAKGcAAAABQjkDAAAIEMoZAABAgFDOAAAAAoRyBgAAECD/Hx7lKaRTqkRCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_sigmoid():\n",
    "    z = np.linspace(-10, 10, 100)\n",
    "\n",
    "    y = sigmoid(z)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(z, y)\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$\\sigma(z)$')\n",
    "    \n",
    "def sigmoid(z): \n",
    "    return 1./(1+np.exp(-z))\n",
    "demo_sigmoid() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/prob.png\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи\n",
    "Будем требовать, чтобы алгоритм возвращал вероятность класса $y=1$:\n",
    "$$h(x,w) = p(y=1|x,w) = \\sigma(g(x))$$\n",
    "\n",
    "Выпишем функцию правдоподобия\n",
    "$$ \\mathcal{L}(w) = \\prod_{i=1}^n h(x_i,w)^{[y_i = 1]} (1 - h(x_i,w))^{[y_i = 0]} \\rightarrow \\max_w$$\n",
    "$$ -\\log{\\mathcal{L}(w)} = - \\sum_i^n [y_i = 1]\\cdot\\log{(h(x_i,w))} + {[y_i = 0]}\\cdot\\log{(1-h(x_i,w))} \\rightarrow \\min_w$$\n",
    "$$L(w) = -\\log{\\mathcal{L}(w)} \\rightarrow \\min_w $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм $h$ называется ***логистической регрессией***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из основных функций потерь -- ***Log Loss*** (бинарная классификация), которую мы получили при выводе логрегрессии:\n",
    "$$L = -\\sum_{i=1}^n(\\,\\,y_i \\cdot \\log{a(x_i)} + (1 - y_i) \\cdot \\log(1 - a(x_i))\\,\\,).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случай нескольких классов (>2)\n",
    "\n",
    "* А если классов несколько?\n",
    "    * 1-vs-1\n",
    "    * 1-vs-rest\n",
    "    * Softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Для каждого класса определяется свой набор весов\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "g_1(x)=w_{1}^{T}x + w_{0,1} \\\\\n",
    "g_{2}(x)=w_{2}^{T}x + w_{0,2}\\\\\n",
    "\\cdots\\\\\n",
    "g_{C}(x)=w_{C}^{T}x + + w_{0,C}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Нормировка \"скоров\" классов\n",
    "\n",
    "$$\n",
    "p(y=c|x)=softmax(g_c|W, x)=\\frac{exp(w_{c}^{T}x + w_{0,c})}{\\sum_{i}exp(w_{i}^{T}x + w_{0,i})}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Entropy Loss*** (общий случай Log Loss), который мы можем вывести по аналогии с Log Loss:\n",
    "$$L = -\\sum_{i=1}^n <y_i , \\log{a(x_i)}>.$$\n",
    "\n",
    "Здесь $y_i$ и $a(x_i)$ -- вектора размерности $|\\mathcal{Y}|$, у $y_i$ только в одной позиции 1, в остальных -- 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод ближайших соседей\n",
    "\n",
    "### K-Nearest Neighbours\n",
    "\n",
    "$$\n",
    "h(x) = \\frac{1}{n} \\sum_{x_j \\in N_K(x)} f(x_j).\n",
    "$$\n",
    "\n",
    "$N_K(\\mathbf{x})$ -- $K$ ближайших соседей для вектора $x$ в обучающем наборе (то есть среди $x_1, ... , x_n$).\n",
    "\n",
    "Как можно использовать для бинарной классификации? А когда классов > 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Байесовский наивный классификатор (Naive Bayes)\n",
    "\n",
    "Дано:\n",
    "\n",
    "$x \\in \\mathcal{X}$ - вектор признаков. Наивность алгоритма характеризуется предположением о том, что компоненты вектора $x$ являются **независимыми** между собой случайными величинами.\n",
    "\n",
    "$C_k \\in \\mathcal{Y}, \\; k = 1,\\ldots,|\\mathcal{Y}|$ - целевая переменная (класс).\n",
    "\n",
    "Теорема Байеса\n",
    "$$\n",
    "P(C_k \\mid x) = \\frac{p(x \\mid C_k) p(C_k)}{p(x)} \\propto p(x \\mid C_k) p(C_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из независимости компонент $x$:\n",
    "$$p(x \\mid C_k) = \\prod_j p_j(x[j] \\mid C_k).$$\n",
    "\n",
    "Таким образом обучение состоит в оценке плотностей $p_j(x[j] \\mid C_k), p(C_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание производится с помощью принципа Maximum A-Posteriori:\n",
    "$$\n",
    "C_{MAP} = \\arg \\max_k p(C_k \\mid x) = \\arg \\max_k p(C_k)\\prod_j p_j(x[j] \\mid C_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Байесовский классификатор — широкий класс алгоритмов классификации, основанный на принципе максимума апостериорной вероятности.  \n",
    "Для классифицируемого объекта вычисляются функции правдоподобия каждого из классов, по ним вычисляются апостериорные вероятности классов.  \n",
    "Объект относится к тому классу, для которого апостериорная вероятность максимальна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "|d | Текст | Класс |\n",
    "|--|--|--|\n",
    "|1 | котики такие мокрые | мимими |\n",
    "|2 | пушистые котики няшки | мимими |\n",
    "|3 | морские котики  | не мимими |\n",
    "|4 | мокрые морские свинки | не мимими |\n",
    "|5 | котики мокрые | ???|\n",
    "\n",
    "С помощью алгоритма MultinomialNB (считаем токены) вычислить $p(\\text{мимими} | d_5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что еще есть: SVM, SVM + kernel trick, Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src=\"images_pt1/prec1.png\" style=\"height:400px\"></td>\n",
    "<td><img src=\"images_pt1/prec2.png\" style=\"height:400px\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Accuracy = \\frac{1}{n}\\sum_{i=1}^n [a(x_i) = y_i]$$\n",
    "\n",
    "$$Precision = \\sum_{i=1}^n \\frac{[a(x_i) = y_i = 1]}{[a(x_i) = 1]}$$\n",
    "\n",
    "$$Recall = \\sum_{i=1}^n \\frac{[a(x_i) = y_i = 1]}{[y_i = 1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F мера\n",
    "\n",
    "$$F1 = 2 \\cdot \\frac{Recall \\cdot Precision}{Recall + Precision}.$$\n",
    "\n",
    "$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{Recall \\cdot Precision}{Recall + \\beta^2 \\cdot Precision}.$$\n",
    "\n",
    "$$F_\\beta = \\left({\\frac {\\alpha }{Precision}}+{\\frac {1-\\alpha }{Recall}}\\right)^{-1}, \\,\\,\n",
    "\\alpha ={\\frac {1}{1+\\beta ^{2}}}.$$\n",
    "\n",
    "`Measures the effectiveness of retrieval with respect to a user who attaches β times as much importance to recall as precision.` ([wiki](https://en.wikipedia.org/wiki/F1_score))\n",
    "\n",
    "При $\\beta \\to \\infty$ получаем $F_\\beta \\to Recall$.\n",
    "\n",
    "При $\\beta \\to 0$ получаем $F_\\beta \\to Precision$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC\n",
    "\n",
    "Для задачи бинарной классификации алгоритм $a$ может выдавать не просто метку из $\\mathcal{Y}$, а некоторое число (скор, вероятность). Чтобы сказать какая метка будет на выходе алгоритма используют порог $\\alpha$ так, что:\n",
    "\n",
    "$$\\hat{y}_i =\n",
    "\t \\begin{cases}{}\n",
    "\t \t1, &\\text{если } a(x_i) \\geq \\alpha, \\\\\n",
    "\t \t0, &\\text{если } a(x_i) < \\alpha.\n",
    "\t \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/tp_fp.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от этого порога у нас будут получаться разные предсказания на одних и тех же данных. Следовательно и метрики качества, определенные выше, будут разные. Определим следующие величины:\n",
    "\n",
    "$$TPR = \\frac{TP}{TP+FN}, \\,\\, FPR = \\frac{FP}{FP+TN}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разных значений порога $-\\infty < \\alpha < +\\infty$ посчитает значения TPR (True Positive Rate) и FPR (False Positive Rate) и отложим их на графике:\n",
    "\n",
    "<img src=\"images_pt1/roc_auc.png\" style=\"height:400px\">\n",
    "\n",
    "Площадь под графиком и является метрикой ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерпретация через непрерывные случайные величины:\n",
    "\n",
    "<img src=\"images_pt1/roc_auc_interpret.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR-AUC\n",
    "По аналогии с ROC-AUC, только по осям у нас Precision и Recall.\n",
    "\n",
    "<img src=\"images_pt1/pr_auc.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence (Расстояние Кульбака — Лейблера)\n",
    "\n",
    "$$D_{KL}(P\\parallel Q)=\\sum \\limits _{i=1}^{n}p_{i}\\log {\\frac {p_{i}}{q_{i}}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/class3.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уравнение прямой задаётся как: $$g(x) = w_0 + w_1x_1 + w_2x_2 = w_0 + \\langle w, x \\rangle = w_0 +  w^\\top x $$\n",
    "\n",
    "* Если $g(x^*) > 0$, то $y^* = \\text{'черный'} = +1$\n",
    "* Если $g(x^*) < 0$, то $y^* = \\text{'белый'} = -1$ (немного поменяем обозначения для простоты изложения)\n",
    "* Если $g(x^*) = 0$, то мы находимся на линии\n",
    "* т.е. решающее правило: $y^* = sign(g(x^*))$\n",
    "\n",
    "Некоторые геометрические особенности\n",
    "* $\\frac{|g(x)|}{||w||}$ - расстояние от точки $x$ до гиперплоскости, степень \"уверенности\" в классификациий\n",
    "* Величину $M = y(\\langle w, x \\rangle + w_0) = y \\cdot g(x)$ называют **отступом**(margin)\n",
    "\n",
    "Если для какого-то объекта $M \\geq 0$, то его классификация выполнена успешно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Линейноразделимый случай с двумя классами\n",
    "* Заметим что $g(x) = w_0 + \\langle w, x \\rangle$ и $g'(x) = c \\cdot (w_0 + \\langle w, x \\rangle)$, $\\forall c>0$ задают одну и ту же гиперплоскость\n",
    "* Подберем $c$ таким образом, чтобы $\\min\\limits_i M_i = \\min\\limits_i y \\cdot g(x_i) = 1$\n",
    "\n",
    "<center><img src='./images_pt1/margin.png'></center>\n",
    "\n",
    "* Таким образом выполняются следующие неравенства:\n",
    "    * $w_0 + \\langle w, x_i \\rangle \\geq 1$, если $y_i = + 1$\n",
    "    * $w_0 + \\langle w, x_i \\rangle \\leq - 1$, если $y_i = - 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разделяющая полоса:  $ -1 \\leq w_0 + \\langle w, x \\rangle \\leq +1$\n",
    "* Ширина разделяющей полосы:\n",
    " $$\\langle (x_{+} -  x_{-}) , \\frac{w}{||w||}\\rangle = \\frac{\\langle w, x_{+} \\rangle - \\langle w, x_{-} \\rangle }{||w||} = \\frac{2}{||w||}  \\rightarrow \\max$$\n",
    " \n",
    " \n",
    "* Таким образом мы придем к оптимизационной задаче:\n",
    "$$\n",
    "\\begin{cases} \n",
    "   \\frac{1}{2} ||w||^2  \\rightarrow \\min  \\\\\n",
    "   y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 \\quad i=1\\dots n\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По теореме Куна-Таккера:\n",
    "\n",
    "\n",
    "$$\\begin{cases} \n",
    "   \\mathcal{L}(w,w_0,\\lambda) = \\frac{1}{2} ||w||^2  - \\sum\\limits_i \\lambda_i \\left( y^{(i)}(\\langle w, x \\rangle + w_0 )  - 1\\right)  \\rightarrow \\min\\limits_{w,w_0}\\max\\limits_{\\lambda}  \\\\\n",
    "   \\lambda_i \\geq 0 \\quad i=1\\dots n\\\\\n",
    "   \\lambda_i = 0 \\text{, либо }  \\langle w, x^{(i)} \\rangle + w_0 = y^{(i)} \\quad i=1\\dots n\n",
    "\\end{cases}$$\n",
    "Объекты, для которых  $\\lambda_i \\neq 0$ называются ** опорными ** \n",
    "\n",
    "\n",
    "Необходимое условие:\n",
    "*  $\\frac{\\partial \\mathcal{L} }{\\partial w} = w - \\sum\\limits_i \\lambda_iy_ix_i = 0 \\quad \\Rightarrow  \\quad w = \\sum\\limits_i \\lambda_iy_ix_i$\n",
    "*  $\\frac{\\partial \\mathcal{L} }{\\partial w_0} = \\sum\\limits_i \\lambda_iy_i = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Сопряжённая задача) Если подставить  эти результаты в $\\mathcal{L}$ то получится\n",
    "$$\\begin{cases}\n",
    "\\mathcal{L}(\\lambda) = \\sum\\limits_i\\lambda_i  - \\frac{1}{2} \\sum\\limits_i\\sum\\limits_j \\lambda_i \\lambda_j  y_i y_j (\\langle x_i, x_j \\rangle)  \\rightarrow \\max\\limits_\\lambda  \\\\\n",
    "\\lambda_i \\geq 0 \\quad i=1\\dots n \\\\\n",
    "\\sum\\limits_i \\lambda_iy_i = 0\n",
    "\\end{cases}$$\n",
    "\n",
    "* **Зависит не от самих объектов, а от их скалярного произведения! **\n",
    "* $\\mathcal{L}(\\lambda)$ - выпуклая и ограниченная сверху функция.\n",
    "* Имеем единственное решение при линейной разделимости\n",
    "* Находим $\\lambda_i,$ из $w = \\sum\\limits_i \\lambda_iy_ix_i$ находим коэффициенты $w$.\n",
    "* Свободный член $w_0$ определяется как среднее или медиана $\\{\\langle w, x_i \\rangle - y_i: \\lambda_i \\neq 0\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:59.547843Z",
     "start_time": "2019-10-31T20:50:58.785859Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print('Так надо')\n",
    "\n",
    "def plot_svc_log_decision_function(clf1, clf2, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 30)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 30)\n",
    "    XX, YY = np.meshgrid(x, y)\n",
    "    XY = np.c_[XX.ravel(), YY.ravel()]\n",
    "    P1 = clf1.decision_function(XY)\n",
    "    P1 = P1.reshape(XX.shape)\n",
    "    \n",
    "    P2 = clf2.decision_function(XY)\n",
    "    P2 = P2.reshape(XX.shape)\n",
    "    # plot the margins\n",
    "    cplot = ax.contour(XX, YY, P1, colors='k', label='svm',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    ax.clabel(cplot, inline=1, fontsize=10)\n",
    "    \n",
    "    ax.contour(XX, YY, P2, colors='r', label='logreg',\n",
    "               levels=[0], alpha=0.5,\n",
    "               linestyles=['-'])\n",
    "\n",
    "    \n",
    "def plot_svc_decision_function(clf1, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 30)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 30)\n",
    "    XX, YY = np.meshgrid(x, y)\n",
    "    XY = np.c_[XX.ravel(), YY.ravel()]\n",
    "    P1 = clf1.decision_function(XY)\n",
    "    P1 = P1.reshape(XX.shape)\n",
    "    \n",
    "    # plot the margins\n",
    "    cplot = ax.contour(XX, YY, P1, colors='k', label='svm',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    ax.clabel(cplot, inline=1, fontsize=10)\n",
    "    \n",
    "\n",
    "def lin_sep_svm_demo(class_sep=2):\n",
    "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2, class_sep=class_sep, scale=1,\n",
    "                                n_redundant=0, n_clusters_per_class=1, random_state=31)\n",
    "    # x_line = np.linspace(np.min(X) - 0.5, np.max(X) + 0.5)\n",
    "\n",
    "    lin_svm = SVC(kernel='linear', C=100).fit(X, y)\n",
    "    \n",
    "    log_reg = LogisticRegression(C=100).fit(X, y)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='autumn')\n",
    "    plot_svc_log_decision_function(lin_svm, log_reg)\n",
    "    # plt.scatter(lin_svm.support_vectors_[:, 0], lin_svm.support_vectors_[:, 1],\n",
    "    #        s=200, facecolors='none')\n",
    "    \n",
    "    \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "    plt.xlim(-2, 5)\n",
    "    plt.ylim(-3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:59.979482Z",
     "start_time": "2019-10-31T20:50:59.550810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e69e924bee3405e89d9e9bc4a5d3e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='class_sep', max=4.0, min=0.4), Output()), _dom_class…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lin_sep_svm_demo(class_sep=2)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lin_sep_svm_demo, class_sep=FloatSlider(min=0.4, max=4, step=0.1, value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неразделимый случай \n",
    "\n",
    "Будем допускать пропуск объектов за разделительную линию\n",
    "* Вместо условия $y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1$\n",
    "* Будет условие $y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0$\n",
    "\n",
    "<center><img src='./images_pt1/slack.png'></center>\n",
    "\n",
    "А целевой функционал заменим на \n",
    "\n",
    "$$ \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы придем к оптимизационной задаче:\n",
    "$$\n",
    "\\begin{cases} \n",
    "   \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi} \\\\\n",
    "   y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 - \\xi_i \\quad i=1\\dots n \\\\\n",
    "   \\xi_i \\geq 0 \\quad i=1\\dots n\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условия Куна-Таккера, необходимые условия оптимума $\\rightarrow$ получаем сопряженную задачу\n",
    "$$\\begin{cases}\n",
    "\\mathcal{L}(\\lambda) = \\sum\\limits_i\\lambda_i  - \\frac{1}{2} \\sum\\limits_i\\sum\\limits_j \\lambda_i \\lambda_j  y_i y_j (\\langle x_i, x_j \\rangle)  \\rightarrow \\max\\limits_\\lambda  \\\\\n",
    "0 \\leq \\lambda_i \\leq C \\quad i=1\\dots n \\\\\n",
    "\\sum\\limits_i \\lambda_iy_i = 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что изначальный целевой функционал\n",
    "$$ \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi}  $$\n",
    "Можно представить в виде\n",
    "$$ \\frac{1}{2С} ||w||^2 + \\sum\\limits_i(1-M_i)_+ \\rightarrow \\min\\limits_{w,w_0}, $$\n",
    "где $M_i$ - это отступ объекта  $x^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:59.991432Z",
     "start_time": "2019-10-31T20:50:59.983326Z"
    }
   },
   "outputs": [],
   "source": [
    "def lin_sep_svm_demo_C(class_sep=2, C=10):\n",
    "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2, class_sep=class_sep, scale=1,\n",
    "                                n_redundant=0, n_clusters_per_class=1, random_state=31)\n",
    "    # x_line = np.linspace(np.min(X) - 0.5, np.max(X) + 0.5)\n",
    "\n",
    "    lin_svm = SVC(kernel='linear', C=C).fit(X, y)\n",
    "    \n",
    "    log_reg = LogisticRegression(C=C).fit(X, y)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='autumn')\n",
    "    plot_svc_log_decision_function(lin_svm, log_reg)\n",
    "    plt.scatter(lin_svm.support_vectors_[:, 0], lin_svm.support_vectors_[:, 1],\n",
    "            s=200, facecolors='none')\n",
    "    \n",
    "    \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "    plt.xlim(-2, 5)\n",
    "    plt.ylim(-3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:51:00.305740Z",
     "start_time": "2019-10-31T20:50:59.994494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7682a4dbf4c64be1a2b5e07e7688708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='class_sep', max=4.0, min=0.2, step=0.2), FloatSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lin_sep_svm_demo_C(class_sep=2, C=10)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lin_sep_svm_demo_C, class_sep=FloatSlider(min=0.2, max=4, value=2, step=0.2), C=FloatSlider(min=0.002, max=10, step=0.002, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще есть kernel trick -- делаем преобразование пространства так, что в новом пространстве классы линейно разделимы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
